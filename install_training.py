#!/usr/bin/env python3
"""
NovaMindè®­ç»ƒæ¡†æ¶å®‰è£…è„šæœ¬

è‡ªåŠ¨æ£€æŸ¥å’Œå®‰è£…è®­ç»ƒæ¡†æ¶æ‰€éœ€çš„ä¾èµ–åŒ…ï¼Œ
å¹¶è®¾ç½®å¿…è¦çš„ç¯å¢ƒé…ç½®ã€‚
"""

import subprocess
import sys
import os
from pathlib import Path


def check_python_version():
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    print("ğŸ æ£€æŸ¥Pythonç‰ˆæœ¬...")
    
    if sys.version_info < (3, 8):
        print("âŒ Pythonç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬")
        print(f"   å½“å‰ç‰ˆæœ¬: {sys.version}")
        return False
    
    print(f"âœ… Pythonç‰ˆæœ¬æ£€æŸ¥é€šè¿‡: {sys.version}")
    return True


def check_cuda_availability():
    """æ£€æŸ¥CUDAå¯ç”¨æ€§"""
    print("ğŸ”§ æ£€æŸ¥CUDAå¯ç”¨æ€§...")
    
    try:
        import torch
        if torch.cuda.is_available():
            cuda_version = torch.version.cuda
            device_count = torch.cuda.device_count()
            print(f"âœ… CUDAå¯ç”¨: ç‰ˆæœ¬ {cuda_version}, è®¾å¤‡æ•°é‡: {device_count}")
            
            for i in range(device_count):
                device_name = torch.cuda.get_device_name(i)
                memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                print(f"   GPU {i}: {device_name} ({memory:.1f}GB)")
            
            return True
        else:
            print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆæ€§èƒ½å¯èƒ½å—é™ï¼‰")
            return False
    except ImportError:
        print("âš ï¸  PyTorchæœªå®‰è£…ï¼Œæ— æ³•æ£€æŸ¥CUDA")
        return False


def install_package(package, upgrade=False):
    """å®‰è£…PythonåŒ…"""
    try:
        cmd = [sys.executable, "-m", "pip", "install"]
        if upgrade:
            cmd.append("--upgrade")
        cmd.append(package)
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            print(f"âœ… {package} å®‰è£…æˆåŠŸ")
            return True
        else:
            print(f"âŒ {package} å®‰è£…å¤±è´¥: {result.stderr}")
            return False
    except Exception as e:
        print(f"âŒ {package} å®‰è£…å‡ºé”™: {e}")
        return False


def install_core_dependencies():
    """å®‰è£…æ ¸å¿ƒä¾èµ–"""
    print("ğŸ“¦ å®‰è£…æ ¸å¿ƒä¾èµ–...")
    
    core_packages = [
        "torch>=2.0.0",
        "transformers>=4.30.0",
        "datasets>=2.12.0",
        "accelerate>=0.20.0",
        "peft>=0.4.0"
    ]
    
    success_count = 0
    for package in core_packages:
        if install_package(package):
            success_count += 1
    
    print(f"ğŸ“Š æ ¸å¿ƒä¾èµ–å®‰è£…å®Œæˆ: {success_count}/{len(core_packages)}")
    return success_count == len(core_packages)


def install_monitoring_dependencies():
    """å®‰è£…ç›‘æ§ä¾èµ–"""
    print("ğŸ“Š å®‰è£…ç›‘æ§ä¾èµ–...")
    
    monitoring_packages = [
        "wandb>=0.15.0",
        "plotly>=5.15.0",
        "fastapi>=0.100.0",
        "uvicorn>=0.23.0",
        "websockets>=11.0.0"
    ]
    
    success_count = 0
    for package in monitoring_packages:
        if install_package(package):
            success_count += 1
    
    print(f"ğŸ“Š ç›‘æ§ä¾èµ–å®‰è£…å®Œæˆ: {success_count}/{len(monitoring_packages)}")
    return success_count == len(monitoring_packages)


def install_utility_dependencies():
    """å®‰è£…å·¥å…·ä¾èµ–"""
    print("ğŸ› ï¸ å®‰è£…å·¥å…·ä¾èµ–...")
    
    utility_packages = [
        "pandas>=2.0.0",
        "numpy>=1.24.0",
        "loguru>=0.7.0",
        "pydantic>=2.0.0",
        "psutil>=5.9.0",
        "tqdm>=4.65.0"
    ]
    
    success_count = 0
    for package in utility_packages:
        if install_package(package):
            success_count += 1
    
    print(f"ğŸ“Š å·¥å…·ä¾èµ–å®‰è£…å®Œæˆ: {success_count}/{len(utility_packages)}")
    return success_count == len(utility_packages)


def create_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    print("ğŸ“ åˆ›å»ºç›®å½•ç»“æ„...")
    
    directories = [
        "./data",
        "./outputs",
        "./logs",
        "./models",
        "./checkpoints",
        "./cache"
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        print(f"âœ… åˆ›å»ºç›®å½•: {directory}")


def create_sample_config():
    """åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶"""
    print("âš™ï¸ åˆ›å»ºç¤ºä¾‹é…ç½®...")
    
    config_content = """# NovaMindè®­ç»ƒæ¡†æ¶ç¤ºä¾‹é…ç½®

# ç¯å¢ƒé…ç½®
environment:
  base_dir: "./novamind"
  data_dir: "./data"
  output_dir: "./outputs"
  log_dir: "./logs"
  model_cache_dir: "./models"
  checkpoint_dir: "./checkpoints"
  monitor_port: 8080
  enable_wandb: true

# é»˜è®¤è®­ç»ƒé…ç½®
default_training:
  model_preset: "dialo-gpt-small"
  training_preset: "quick"
  batch_size: 4
  learning_rate: 5e-5
  num_epochs: 3
  max_length: 512

# ç›‘æ§é…ç½®
monitoring:
  log_interval: 10
  eval_interval: 50
  save_interval: 100
  enable_wandb: true
  wandb_project: "novamind-training"
"""
    
    config_path = Path("./training_config.yaml")
    with open(config_path, "w", encoding="utf-8") as f:
        f.write(config_content)
    
    print(f"âœ… é…ç½®æ–‡ä»¶å·²åˆ›å»º: {config_path}")


def test_installation():
    """æµ‹è¯•å®‰è£…"""
    print("ğŸ§ª æµ‹è¯•å®‰è£…...")
    
    try:
        # æµ‹è¯•æ ¸å¿ƒæ¨¡å—å¯¼å…¥
        import torch
        import transformers
        import datasets
        import wandb
        import plotly
        import fastapi
        
        print("âœ… æ ¸å¿ƒæ¨¡å—å¯¼å…¥æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•CUDA
        if torch.cuda.is_available():
            print("âœ… CUDAæµ‹è¯•é€šè¿‡")
        else:
            print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
        
        # æµ‹è¯•è®­ç»ƒæ¡†æ¶
        try:
            from training.trainer import BaseTrainer, TrainingConfig
            from training.llm_trainer import LLMTrainer
            from training.monitor import TrainingMonitor
            print("âœ… è®­ç»ƒæ¡†æ¶æ¨¡å—å¯¼å…¥æµ‹è¯•é€šè¿‡")
        except ImportError as e:
            print(f"âš ï¸  è®­ç»ƒæ¡†æ¶æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        
        return True
        
    except ImportError as e:
        print(f"âŒ æ¨¡å—å¯¼å…¥æµ‹è¯•å¤±è´¥: {e}")
        return False


def show_next_steps():
    """æ˜¾ç¤ºåç»­æ­¥éª¤"""
    print("\nğŸ‰ å®‰è£…å®Œæˆï¼")
    print("=" * 50)
    print("ğŸ“– åç»­æ­¥éª¤:")
    print("1. æŸ¥çœ‹å¿«é€Ÿå¼€å§‹æŒ‡å—:")
    print("   python -m training.quick_start")
    print()
    print("2. è¿è¡Œè®­ç»ƒç¤ºä¾‹:")
    print("   python -m training.example")
    print()
    print("3. æŸ¥çœ‹ä¼˜åŠ¿æ¼”ç¤º:")
    print("   python -m training.advantages_demo")
    print()
    print("4. å¯åŠ¨ç›‘æ§æœåŠ¡å™¨:")
    print("   python -c 'from training.monitor import training_monitor; training_monitor.start()'")
    print()
    print("5. è®¿é—®ç›‘æ§ç•Œé¢:")
    print("   http://localhost:8080")
    print()
    print("ğŸ“š æ›´å¤šä¿¡æ¯è¯·æŸ¥çœ‹:")
    print("   - README.md")
    print("   - training/example.py")
    print("   - training/quick_start.py")


def main():
    """ä¸»å®‰è£…å‡½æ•°"""
    print("ğŸš€ NovaMindè®­ç»ƒæ¡†æ¶å®‰è£…ç¨‹åº")
    print("=" * 50)
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    if not check_python_version():
        sys.exit(1)
    
    # æ£€æŸ¥CUDA
    check_cuda_availability()
    
    print("\nğŸ“¦ å¼€å§‹å®‰è£…ä¾èµ–...")
    
    # å®‰è£…ä¾èµ–
    core_success = install_core_dependencies()
    monitoring_success = install_monitoring_dependencies()
    utility_success = install_utility_dependencies()
    
    if not (core_success and monitoring_success and utility_success):
        print("âŒ éƒ¨åˆ†ä¾èµ–å®‰è£…å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ‰‹åŠ¨å®‰è£…")
        sys.exit(1)
    
    # åˆ›å»ºç›®å½•ç»“æ„
    create_directories()
    
    # åˆ›å»ºç¤ºä¾‹é…ç½®
    create_sample_config()
    
    # æµ‹è¯•å®‰è£…
    if not test_installation():
        print("âŒ å®‰è£…æµ‹è¯•å¤±è´¥")
        sys.exit(1)
    
    # æ˜¾ç¤ºåç»­æ­¥éª¤
    show_next_steps()


if __name__ == "__main__":
    main() 