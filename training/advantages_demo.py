"""
NovaMindè®­ç»ƒæ¡†æ¶ä¼˜åŠ¿æ¼”ç¤º

å±•ç¤ºNovaMindè®­ç»ƒæ¡†æ¶ç›¸æ¯”å…¶ä»–æ¡†æ¶ï¼ˆå¦‚LangChainï¼‰çš„ç‹¬ç‰¹ä¼˜åŠ¿ï¼š
1. å®æ—¶ç›‘æ§å’Œå¯è§†åŒ–
2. æ™ºèƒ½å‚æ•°è°ƒä¼˜
3. å¤šæ¨¡æ€è®­ç»ƒæ”¯æŒ
4. åˆ†å¸ƒå¼è®­ç»ƒ
5. æ¨¡å‹ç‰ˆæœ¬ç®¡ç†
6. å®éªŒç®¡ç†
7. ç”Ÿäº§å°±ç»ª
"""

import asyncio
import time
from pathlib import Path
from typing import Dict, Any, List

from .trainer import TrainingManager, training_manager
from .llm_trainer import LLMTrainer
from .config import (
    get_training_config,
    get_lora_config,
    get_instruction_config,
    list_available_presets
)
from .monitor import training_monitor, MetricsCallback


class NovaMindAdvantagesDemo:
    """NovaMindè®­ç»ƒæ¡†æ¶ä¼˜åŠ¿æ¼”ç¤ºç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¼”ç¤º"""
        self.training_manager = training_manager
        self.monitor = training_monitor
        self.demo_results = {}
    
    def demonstrate_advantage_1_realtime_monitoring(self):
        """ä¼˜åŠ¿1ï¼šå®æ—¶ç›‘æ§å’Œå¯è§†åŒ–"""
        print("ğŸ¯ ä¼˜åŠ¿1ï¼šå®æ—¶ç›‘æ§å’Œå¯è§†åŒ–")
        print("=" * 50)
        
        # å¯åŠ¨ç›‘æ§æœåŠ¡å™¨
        self.monitor.start_background()
        print("âœ… ç›‘æ§æœåŠ¡å™¨å·²å¯åŠ¨: http://localhost:8080")
        print("   å®æ—¶æŸ¥çœ‹è®­ç»ƒçŠ¶æ€ã€æŸå¤±æ›²çº¿ã€ç³»ç»Ÿèµ„æº")
        print("   æ”¯æŒWebSocketå®æ—¶æ•°æ®æ¨é€")
        print("   æä¾›äº¤äº’å¼å›¾è¡¨å’Œä»ªè¡¨æ¿")
        print()
        
        # åˆ›å»ºç¤ºä¾‹è®­ç»ƒ
        config = get_training_config(
            model_preset="dialo-gpt-small",
            training_preset="quick",
            dataset_path="./data/sample_data.json",
            training_name="demo_monitoring"
        )
        
        trainer = LLMTrainer(config)
        trainer.add_callback(MetricsCallback("demo_monitoring"))
        
        # å¯åŠ¨è®­ç»ƒ
        training_id = self.training_manager.start_training("demo_monitoring", trainer)
        print(f"âœ… æ¼”ç¤ºè®­ç»ƒå·²å¯åŠ¨: {training_id}")
        print("   è®¿é—® http://localhost:8080 æŸ¥çœ‹å®æ—¶ç›‘æ§")
        print()
        
        return training_id
    
    def demonstrate_advantage_2_smart_parameter_tuning(self):
        """ä¼˜åŠ¿2ï¼šæ™ºèƒ½å‚æ•°è°ƒä¼˜"""
        print("ğŸ§  ä¼˜åŠ¿2ï¼šæ™ºèƒ½å‚æ•°è°ƒä¼˜")
        print("=" * 50)
        
        # å±•ç¤ºé¢„è®¾é…ç½®ç³»ç»Ÿ
        presets = list_available_presets()
        print("ğŸ“‹ æ™ºèƒ½é¢„è®¾é…ç½®ç³»ç»Ÿ:")
        print(f"   æ¨¡å‹é¢„è®¾: {len(presets['model_presets'])} ç§")
        print(f"   è®­ç»ƒé¢„è®¾: {len(presets['training_presets'])} ç§")
        print(f"   LoRAé¢„è®¾: {len(presets['lora_presets'])} ç§")
        print()
        
        # å±•ç¤ºè‡ªåŠ¨å‚æ•°è°ƒä¼˜
        print("âš¡ è‡ªåŠ¨å‚æ•°è°ƒä¼˜åŠŸèƒ½:")
        print("   - åŸºäºæ€§èƒ½è‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡")
        print("   - æ™ºèƒ½æ—©åœæœºåˆ¶")
        print("   - åŠ¨æ€æ‰¹æ¬¡å¤§å°è°ƒæ•´")
        print("   - è‡ªé€‚åº”æ¢¯åº¦è£å‰ª")
        print()
        
        # åˆ›å»ºå¤šä¸ªé…ç½®è¿›è¡Œå¯¹æ¯”
        configs = {
            "quick": get_training_config("dialo-gpt-small", "quick", "./data/sample_data.json", "demo_quick"),
            "standard": get_training_config("dialo-gpt-small", "standard", "./data/sample_data.json", "demo_standard"),
            "high_quality": get_training_config("dialo-gpt-small", "high_quality", "./data/sample_data.json", "demo_quality")
        }
        
        print("ğŸ”¬ é…ç½®å¯¹æ¯”å®éªŒ:")
        for name, config in configs.items():
            print(f"   {name}: LR={config.learning_rate}, BS={config.batch_size}, Epochs={config.num_epochs}")
        print()
        
        return configs
    
    def demonstrate_advantage_3_multimodal_support(self):
        """ä¼˜åŠ¿3ï¼šå¤šæ¨¡æ€è®­ç»ƒæ”¯æŒ"""
        print("ğŸ¨ ä¼˜åŠ¿3ï¼šå¤šæ¨¡æ€è®­ç»ƒæ”¯æŒ")
        print("=" * 50)
        
        print("ğŸ“Š æ”¯æŒçš„å¤šæ¨¡æ€ç±»å‹:")
        print("   - æ–‡æœ¬æ¨¡å‹ (LLM)")
        print("   - è§†è§‰æ¨¡å‹ (Vision)")
        print("   - éŸ³é¢‘æ¨¡å‹ (Audio)")
        print("   - å¤šæ¨¡æ€æ¨¡å‹ (Multimodal)")
        print()
        
        print("ğŸ”„ ç»Ÿä¸€è®­ç»ƒæ¥å£:")
        print("   - ç›¸åŒçš„é…ç½®ç³»ç»Ÿ")
        print("   - ç»Ÿä¸€çš„ç›‘æ§ç•Œé¢")
        print("   - ä¸€è‡´çš„APIæ¥å£")
        print("   - è·¨æ¨¡æ€å®éªŒç®¡ç†")
        print()
        
        # å±•ç¤ºä¸åŒæ¨¡æ€çš„é…ç½®
        multimodal_configs = {
            "text": get_training_config("dialo-gpt-small", "standard", "./data/text_data.json", "demo_text"),
            "vision": get_training_config("vision-model", "standard", "./data/vision_data.json", "demo_vision"),
            "audio": get_training_config("audio-model", "standard", "./data/audio_data.json", "demo_audio")
        }
        
        print("ğŸ¯ å¤šæ¨¡æ€é…ç½®ç¤ºä¾‹:")
        for modality, config in multimodal_configs.items():
            print(f"   {modality}: {config.model_type} - {config.model_path}")
        print()
        
        return multimodal_configs
    
    def demonstrate_advantage_4_distributed_training(self):
        """ä¼˜åŠ¿4ï¼šåˆ†å¸ƒå¼è®­ç»ƒ"""
        print("âš¡ ä¼˜åŠ¿4ï¼šåˆ†å¸ƒå¼è®­ç»ƒ")
        print("=" * 50)
        
        print("ğŸŒ åˆ†å¸ƒå¼è®­ç»ƒç‰¹æ€§:")
        print("   - å¤šGPUè‡ªåŠ¨å¹¶è¡Œ")
        print("   - å¤šèŠ‚ç‚¹é›†ç¾¤æ”¯æŒ")
        print("   - è‡ªåŠ¨è´Ÿè½½å‡è¡¡")
        print("   - æ•…éšœæ¢å¤æœºåˆ¶")
        print("   - é€šä¿¡ä¼˜åŒ–")
        print()
        
        # å±•ç¤ºåˆ†å¸ƒå¼é…ç½®
        distributed_config = get_training_config(
            model_preset="llama-7b",
            training_preset="high_quality",
            dataset_path="./data/large_dataset.json",
            training_name="demo_distributed"
        )
        distributed_config.distributed = True
        distributed_config.num_gpus = 4
        
        print("ğŸ”§ åˆ†å¸ƒå¼é…ç½®ç¤ºä¾‹:")
        print(f"   åˆ†å¸ƒå¼æ¨¡å¼: {distributed_config.distributed}")
        print(f"   GPUæ•°é‡: {distributed_config.num_gpus}")
        print(f"   æ‰¹æ¬¡å¤§å°: {distributed_config.batch_size}")
        print(f"   æ¢¯åº¦ç´¯ç§¯: {distributed_config.gradient_accumulation_steps}")
        print()
        
        return distributed_config
    
    def demonstrate_advantage_5_model_versioning(self):
        """ä¼˜åŠ¿5ï¼šæ¨¡å‹ç‰ˆæœ¬ç®¡ç†"""
        print("ğŸ“¦ ä¼˜åŠ¿5ï¼šæ¨¡å‹ç‰ˆæœ¬ç®¡ç†")
        print("=" * 50)
        
        print("ğŸ”„ ç‰ˆæœ¬ç®¡ç†åŠŸèƒ½:")
        print("   - è‡ªåŠ¨ç‰ˆæœ¬å·ç”Ÿæˆ")
        print("   - æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜")
        print("   - ç‰ˆæœ¬å›æ»šæ”¯æŒ")
        print("   - æ¨¡å‹å¯¹æ¯”åˆ†æ")
        print("   - ç”Ÿäº§éƒ¨ç½²ç®¡ç†")
        print()
        
        # åˆ›å»ºå¤šä¸ªç‰ˆæœ¬çš„è®­ç»ƒ
        versions = ["v1.0", "v1.1", "v2.0"]
        version_configs = {}
        
        for version in versions:
            config = get_training_config(
                model_preset="dialo-gpt-small",
                training_preset="standard",
                dataset_path=f"./data/version_{version}.json",
                training_name=f"demo_version_{version}"
            )
            version_configs[version] = config
        
        print("ğŸ“‹ ç‰ˆæœ¬ç®¡ç†ç¤ºä¾‹:")
        for version, config in version_configs.items():
            print(f"   {version}: {config.model_name} -> {config.output_dir}")
        print()
        
        return version_configs
    
    def demonstrate_advantage_6_experiment_management(self):
        """ä¼˜åŠ¿6ï¼šå®éªŒç®¡ç†"""
        print("ğŸ”¬ ä¼˜åŠ¿6ï¼šå®éªŒç®¡ç†")
        print("=" * 50)
        
        print("ğŸ“Š å®éªŒç®¡ç†åŠŸèƒ½:")
        print("   - A/Bæµ‹è¯•æ”¯æŒ")
        print("   - å®éªŒå¯¹æ¯”åˆ†æ")
        print("   - ç»“æœå¯è§†åŒ–")
        print("   - å®éªŒè¿½è¸ª")
        print("   - æœ€ä½³å®è·µæ¨è")
        print()
        
        # åˆ›å»ºå®éªŒé…ç½®
        experiments = {
            "baseline": get_training_config("dialo-gpt-small", "standard", "./data/baseline.json", "exp_baseline"),
            "lora_8": get_lora_config("dialo-gpt-small", "./data/lora_data.json", "exp_lora_8", "efficient"),
            "lora_16": get_lora_config("dialo-gpt-small", "./data/lora_data.json", "exp_lora_16", "standard"),
            "instruction": get_instruction_config("dialo-gpt-small", "./data/instruction_data.json", "exp_instruction")
        }
        
        print("ğŸ§ª å®éªŒé…ç½®ç¤ºä¾‹:")
        for name, config in experiments.items():
            lora_info = f" (LoRA r={config.lora_config.r})" if config.use_lora else ""
            instruction_info = " (æŒ‡ä»¤å¾®è°ƒ)" if config.instruction_tuning else ""
            print(f"   {name}: {config.model_name}{lora_info}{instruction_info}")
        print()
        
        return experiments
    
    def demonstrate_advantage_7_production_ready(self):
        """ä¼˜åŠ¿7ï¼šç”Ÿäº§å°±ç»ª"""
        print("ğŸ­ ä¼˜åŠ¿7ï¼šç”Ÿäº§å°±ç»ª")
        print("=" * 50)
        
        print("ğŸš€ ç”Ÿäº§çº§ç‰¹æ€§:")
        print("   - ä¼ä¸šçº§å®‰å…¨")
        print("   - é«˜å¯ç”¨æ€§")
        print("   - æ€§èƒ½ä¼˜åŒ–")
        print("   - ç›‘æ§å‘Šè­¦")
        print("   - è‡ªåŠ¨éƒ¨ç½²")
        print("   - å®¹å™¨åŒ–æ”¯æŒ")
        print()
        
        # å±•ç¤ºç”Ÿäº§é…ç½®
        production_config = get_training_config(
            model_preset="llama-7b",
            training_preset="high_quality",
            dataset_path="./data/production_data.json",
            training_name="production_model"
        )
        
        # æ·»åŠ ç”Ÿäº§çº§é…ç½®
        production_config.enable_wandb = True
        production_config.gradient_checkpointing = True
        production_config.mixed_precision = True
        production_config.flash_attention = True
        
        print("âš™ï¸ ç”Ÿäº§é…ç½®ç¤ºä¾‹:")
        print(f"   æ··åˆç²¾åº¦: {production_config.mixed_precision}")
        print(f"   æ¢¯åº¦æ£€æŸ¥ç‚¹: {production_config.gradient_checkpointing}")
        print(f"   Flash Attention: {production_config.flash_attention}")
        print(f"   WandBé›†æˆ: {production_config.enable_wandb}")
        print()
        
        return production_config
    
    def compare_with_langchain(self):
        """ä¸LangChainå¯¹æ¯”"""
        print("ğŸ†š ä¸LangChainè®­ç»ƒæ¡†æ¶å¯¹æ¯”")
        print("=" * 50)
        
        comparison = {
            "å®æ—¶ç›‘æ§": {
                "NovaMind": "âœ… Webç•Œé¢å®æ—¶ç›‘æ§ï¼ŒWebSocketæ¨é€",
                "LangChain": "âŒ åŸºç¡€æ—¥å¿—è¾“å‡º"
            },
            "å‚æ•°è°ƒä¼˜": {
                "NovaMind": "âœ… æ™ºèƒ½é¢„è®¾ç³»ç»Ÿï¼Œè‡ªåŠ¨è°ƒä¼˜",
                "LangChain": "âŒ æ‰‹åŠ¨é…ç½®ï¼Œæ— è‡ªåŠ¨è°ƒä¼˜"
            },
            "å¤šæ¨¡æ€æ”¯æŒ": {
                "NovaMind": "âœ… ç»Ÿä¸€æ¥å£ï¼Œå¤šæ¨¡æ€åŸç”Ÿæ”¯æŒ",
                "LangChain": "âŒ ä¸»è¦é’ˆå¯¹æ–‡æœ¬ï¼Œå¤šæ¨¡æ€æ”¯æŒæœ‰é™"
            },
            "åˆ†å¸ƒå¼è®­ç»ƒ": {
                "NovaMind": "âœ… åŸç”Ÿåˆ†å¸ƒå¼æ”¯æŒï¼Œè‡ªåŠ¨è´Ÿè½½å‡è¡¡",
                "LangChain": "âŒ éœ€è¦é¢å¤–é…ç½®ï¼Œæ”¯æŒæœ‰é™"
            },
            "ç‰ˆæœ¬ç®¡ç†": {
                "NovaMind": "âœ… å®Œæ•´ç‰ˆæœ¬ç®¡ç†ï¼Œè‡ªåŠ¨æ£€æŸ¥ç‚¹",
                "LangChain": "âŒ åŸºç¡€ä¿å­˜åŠŸèƒ½"
            },
            "å®éªŒç®¡ç†": {
                "NovaMind": "âœ… A/Bæµ‹è¯•ï¼Œå®éªŒå¯¹æ¯”åˆ†æ",
                "LangChain": "âŒ æ— å†…ç½®å®éªŒç®¡ç†"
            },
            "ç”Ÿäº§å°±ç»ª": {
                "NovaMind": "âœ… ä¼ä¸šçº§ç‰¹æ€§ï¼Œå®¹å™¨åŒ–éƒ¨ç½²",
                "LangChain": "âŒ ä¸»è¦é¢å‘ç ”ç©¶ï¼Œç”Ÿäº§æ”¯æŒæœ‰é™"
            }
        }
        
        for feature, comparison_data in comparison.items():
            print(f"{feature}:")
            print(f"   NovaMind: {comparison_data['NovaMind']}")
            print(f"   LangChain: {comparison_data['LangChain']}")
            print()
    
    def run_comprehensive_demo(self):
        """è¿è¡Œç»¼åˆæ¼”ç¤º"""
        print("ğŸš€ NovaMindè®­ç»ƒæ¡†æ¶ä¼˜åŠ¿ç»¼åˆæ¼”ç¤º")
        print("=" * 60)
        print()
        
        try:
            # æ¼”ç¤ºå„ä¸ªä¼˜åŠ¿
            self.demonstrate_advantage_1_realtime_monitoring()
            time.sleep(2)
            
            self.demonstrate_advantage_2_smart_parameter_tuning()
            time.sleep(2)
            
            self.demonstrate_advantage_3_multimodal_support()
            time.sleep(2)
            
            self.demonstrate_advantage_4_distributed_training()
            time.sleep(2)
            
            self.demonstrate_advantage_5_model_versioning()
            time.sleep(2)
            
            self.demonstrate_advantage_6_experiment_management()
            time.sleep(2)
            
            self.demonstrate_advantage_7_production_ready()
            time.sleep(2)
            
            # ä¸LangChainå¯¹æ¯”
            self.compare_with_langchain()
            
            print("ğŸ‰ ä¼˜åŠ¿æ¼”ç¤ºå®Œæˆï¼")
            print("ğŸ“– æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹æ–‡æ¡£å’Œç¤ºä¾‹ä»£ç ")
            print("ğŸŒ è®¿é—® http://localhost:8080 æŸ¥çœ‹å®æ—¶ç›‘æ§")
            
        except Exception as e:
            print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()


def create_demo_data():
    """åˆ›å»ºæ¼”ç¤ºæ•°æ®"""
    data_dir = Path("./data")
    data_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®æ–‡ä»¶
    sample_data = [
        {"text": "è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æ–‡æœ¬æ•°æ®ã€‚"},
        {"text": "ç”¨äºæ¼”ç¤ºNovaMindè®­ç»ƒæ¡†æ¶ã€‚"},
        {"text": "æ”¯æŒå¤šç§è®­ç»ƒæ¨¡å¼å’Œé…ç½®ã€‚"}
    ]
    
    import json
    with open(data_dir / "sample_data.json", "w", encoding="utf-8") as f:
        json.dump(sample_data, f, ensure_ascii=False, indent=2)
    
    print("âœ… æ¼”ç¤ºæ•°æ®å·²åˆ›å»º")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ NovaMindè®­ç»ƒæ¡†æ¶ä¼˜åŠ¿æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºæ¼”ç¤ºæ•°æ®
    create_demo_data()
    
    # åˆ›å»ºæ¼”ç¤ºå®ä¾‹
    demo = NovaMindAdvantagesDemo()
    
    # è¿è¡Œç»¼åˆæ¼”ç¤º
    demo.run_comprehensive_demo()
    
    # ä¿æŒç›‘æ§æœåŠ¡å™¨è¿è¡Œ
    try:
        while True:
            await asyncio.sleep(1)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ¼”ç¤ºç»“æŸ")


if __name__ == "__main__":
    asyncio.run(main()) 