"""
NovaMindè®­ç»ƒæ¡†æ¶å¿«é€Ÿå¼€å§‹æŒ‡å—

è¿™ä¸ªæ–‡ä»¶å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨NovaMindè®­ç»ƒæ¡†æ¶è¿›è¡Œå¿«é€Ÿè®­ç»ƒã€‚
åŒ…å«å¤šä¸ªç®€å•æ˜“ç”¨çš„ç¤ºä¾‹ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿä¸Šæ‰‹ã€‚
"""

import asyncio
from pathlib import Path
from typing import Dict, Any

from .trainer import TrainingManager, training_manager
from .llm_trainer import LLMTrainer
from .config import (
    get_training_config,
    get_lora_config,
    get_instruction_config,
    get_conversation_config,
    list_available_presets,
    DEFAULT_ENV_CONFIG
)
from .monitor import training_monitor, MetricsCallback


def quick_start_example():
    """å¿«é€Ÿå¼€å§‹ç¤ºä¾‹"""
    print("ğŸš€ NovaMindè®­ç»ƒæ¡†æ¶å¿«é€Ÿå¼€å§‹")
    print("=" * 50)
    
    # 1. æŸ¥çœ‹å¯ç”¨é¢„è®¾
    presets = list_available_presets()
    print("ğŸ“‹ å¯ç”¨é¢„è®¾é…ç½®:")
    print(f"  æ¨¡å‹é¢„è®¾: {presets['model_presets']}")
    print(f"  è®­ç»ƒé¢„è®¾: {presets['training_presets']}")
    print(f"  LoRAé¢„è®¾: {presets['lora_presets']}")
    print()
    
    # 2. åˆ›å»ºç¯å¢ƒé…ç½®
    DEFAULT_ENV_CONFIG.create_directories()
    print("ğŸ“ ç›®å½•ç»“æ„å·²åˆ›å»º")
    print()
    
    # 3. åˆ›å»ºç¤ºä¾‹æ•°æ®
    create_sample_data()
    print("ğŸ“Š ç¤ºä¾‹æ•°æ®å·²åˆ›å»º")
    print()


def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
    data_dir = Path("./data")
    data_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºç®€å•çš„æ–‡æœ¬æ•°æ®
    sample_texts = [
        "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ã€‚",
        "æœºå™¨å­¦ä¹ ä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ ã€‚",
        "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œæ¨¡å¼è¯†åˆ«ã€‚",
        "è‡ªç„¶è¯­è¨€å¤„ç†è®©è®¡ç®—æœºç†è§£äººç±»è¯­è¨€ã€‚",
        "è®¡ç®—æœºè§†è§‰ä½¿è®¡ç®—æœºèƒ½å¤Ÿç†è§£å›¾åƒã€‚"
    ]
    
    # ä¿å­˜ä¸ºJSONæ ¼å¼
    import json
    text_data = [{"text": text} for text in sample_texts]
    
    with open(data_dir / "sample_texts.json", "w", encoding="utf-8") as f:
        json.dump(text_data, f, ensure_ascii=False, indent=2)
    
    # åˆ›å»ºæŒ‡ä»¤æ•°æ®
    instruction_data = [
        {
            "instruction": "è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½",
            "response": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚"
        },
        {
            "instruction": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
            "response": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚"
        }
    ]
    
    with open(data_dir / "sample_instructions.json", "w", encoding="utf-8") as f:
        json.dump(instruction_data, f, ensure_ascii=False, indent=2)


async def example_1_basic_training():
    """ç¤ºä¾‹1ï¼šåŸºç¡€è®­ç»ƒ"""
    print("ğŸ“š ç¤ºä¾‹1ï¼šåŸºç¡€è¯­è¨€æ¨¡å‹è®­ç»ƒ")
    print("-" * 30)
    
    # ä½¿ç”¨é¢„è®¾é…ç½®åˆ›å»ºè®­ç»ƒé…ç½®
    config = get_training_config(
        model_preset="dialo-gpt-small",  # ä½¿ç”¨å°å‹æ¨¡å‹
        training_preset="quick",         # å¿«é€Ÿè®­ç»ƒ
        dataset_path="./data/sample_texts.json",
        training_name="basic_example"
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = LLMTrainer(config)
    
    # æ·»åŠ ç›‘æ§å›è°ƒ
    trainer.add_callback(MetricsCallback("basic_example"))
    
    # å¯åŠ¨è®­ç»ƒ
    training_id = training_manager.start_training("basic_example", trainer)
    print(f"âœ… è®­ç»ƒå·²å¯åŠ¨ï¼ŒID: {training_id}")
    
    # ç­‰å¾…è®­ç»ƒå®Œæˆ
    await wait_for_training_completion(training_id)
    
    # æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ
    test_text_generation(trainer)
    
    print("âœ… åŸºç¡€è®­ç»ƒç¤ºä¾‹å®Œæˆ\n")


async def example_2_lora_training():
    """ç¤ºä¾‹2ï¼šLoRAå¾®è°ƒ"""
    print("ğŸ¯ ç¤ºä¾‹2ï¼šLoRAå¾®è°ƒè®­ç»ƒ")
    print("-" * 30)
    
    # ä½¿ç”¨LoRAé…ç½®
    config = get_lora_config(
        model_preset="dialo-gpt-small",
        dataset_path="./data/sample_instructions.json",
        training_name="lora_example",
        lora_preset="efficient"  # ä½¿ç”¨é«˜æ•ˆLoRAé…ç½®
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = LLMTrainer(config)
    
    # æ·»åŠ ç›‘æ§å›è°ƒ
    trainer.add_callback(MetricsCallback("lora_example"))
    
    # å¯åŠ¨è®­ç»ƒ
    training_id = training_manager.start_training("lora_example", trainer)
    print(f"âœ… LoRAè®­ç»ƒå·²å¯åŠ¨ï¼ŒID: {training_id}")
    
    # ç­‰å¾…è®­ç»ƒå®Œæˆ
    await wait_for_training_completion(training_id)
    
    print("âœ… LoRAè®­ç»ƒç¤ºä¾‹å®Œæˆ\n")


async def example_3_instruction_tuning():
    """ç¤ºä¾‹3ï¼šæŒ‡ä»¤å¾®è°ƒ"""
    print("ğŸ“ ç¤ºä¾‹3ï¼šæŒ‡ä»¤å¾®è°ƒè®­ç»ƒ")
    print("-" * 30)
    
    # ä½¿ç”¨æŒ‡ä»¤å¾®è°ƒé…ç½®
    config = get_instruction_config(
        model_preset="dialo-gpt-small",
        dataset_path="./data/sample_instructions.json",
        training_name="instruction_example"
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = LLMTrainer(config)
    
    # æ·»åŠ ç›‘æ§å›è°ƒ
    trainer.add_callback(MetricsCallback("instruction_example"))
    
    # å¯åŠ¨è®­ç»ƒ
    training_id = training_manager.start_training("instruction_example", trainer)
    print(f"âœ… æŒ‡ä»¤å¾®è°ƒå·²å¯åŠ¨ï¼ŒID: {training_id}")
    
    # ç­‰å¾…è®­ç»ƒå®Œæˆ
    await wait_for_training_completion(training_id)
    
    # æµ‹è¯•æŒ‡ä»¤å“åº”
    test_instruction_response(trainer)
    
    print("âœ… æŒ‡ä»¤å¾®è°ƒç¤ºä¾‹å®Œæˆ\n")


async def example_4_monitoring():
    """ç¤ºä¾‹4ï¼šç›‘æ§ç³»ç»Ÿ"""
    print("ğŸ“Š ç¤ºä¾‹4ï¼šè®­ç»ƒç›‘æ§ç³»ç»Ÿ")
    print("-" * 30)
    
    # å¯åŠ¨ç›‘æ§æœåŠ¡å™¨
    training_monitor.start_background()
    print("ğŸŒ ç›‘æ§æœåŠ¡å™¨å·²å¯åŠ¨")
    print("   è®¿é—® http://localhost:8080 æŸ¥çœ‹å®æ—¶ç›‘æ§")
    
    # æ˜¾ç¤ºè®­ç»ƒçŠ¶æ€
    trainings = training_manager.list_trainings()
    print(f"ğŸ“ˆ å½“å‰è®­ç»ƒä»»åŠ¡æ•°é‡: {len(trainings)}")
    
    for training in trainings:
        status = training['status']
        print(f"   - {training['id']}: {status['status']}")
    
    print("âœ… ç›‘æ§ç³»ç»Ÿç¤ºä¾‹å®Œæˆ\n")


async def wait_for_training_completion(training_id: str, timeout: int = 300):
    """
    ç­‰å¾…è®­ç»ƒå®Œæˆ
    
    Args:
        training_id: è®­ç»ƒID
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    """
    import time
    start_time = time.time()
    
    while time.time() - start_time < timeout:
        status = training_manager.get_training_status(training_id)
        if status:
            current_status = status['status']
            print(f"   è®­ç»ƒçŠ¶æ€: {current_status}")
            
            if current_status in ['completed', 'failed', 'cancelled']:
                return status
        
        await asyncio.sleep(5)
    
    print(f"   è®­ç»ƒè¶…æ—¶ï¼ŒID: {training_id}")


def test_text_generation(trainer: LLMTrainer):
    """æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ"""
    print("ğŸ§ª æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ:")
    
    test_prompts = [
        "äººå·¥æ™ºèƒ½çš„åº”ç”¨",
        "æœºå™¨å­¦ä¹ çš„ä¼˜åŠ¿"
    ]
    
    for prompt in test_prompts:
        try:
            generated = trainer.generate_text(prompt, max_length=50, temperature=0.7)
            print(f"   æç¤º: {prompt}")
            print(f"   ç”Ÿæˆ: {generated}")
            print()
        except Exception as e:
            print(f"   ç”Ÿæˆå¤±è´¥: {e}")


def test_instruction_response(trainer: LLMTrainer):
    """æµ‹è¯•æŒ‡ä»¤å“åº”"""
    print("ğŸ§ª æµ‹è¯•æŒ‡ä»¤å“åº”:")
    
    test_instructions = [
        "è§£é‡Šä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ",
        "æœºå™¨å­¦ä¹ æœ‰å“ªäº›ç±»å‹ï¼Ÿ"
    ]
    
    for instruction in test_instructions:
        try:
            # æ„å»ºæŒ‡ä»¤æ ¼å¼
            prompt = f"Instruction: {instruction}\nResponse:"
            generated = trainer.generate_text(prompt, max_length=100, temperature=0.7)
            print(f"   æŒ‡ä»¤: {instruction}")
            print(f"   å“åº”: {generated}")
            print()
        except Exception as e:
            print(f"   å“åº”å¤±è´¥: {e}")


def show_usage_tips():
    """æ˜¾ç¤ºä½¿ç”¨æç¤º"""
    print("ğŸ’¡ ä½¿ç”¨æç¤º:")
    print("=" * 50)
    print("1. é€‰æ‹©åˆé€‚çš„æ¨¡å‹é¢„è®¾:")
    print("   - å°å‹æ¨¡å‹ (gpt2-small, dialo-gpt-small): å¿«é€Ÿå®éªŒ")
    print("   - ä¸­å‹æ¨¡å‹ (llama-7b, qwen-7b): å¹³è¡¡æ€§èƒ½")
    print("   - å¤§å‹æ¨¡å‹ (llama-13b): æœ€ä½³æ•ˆæœ")
    print()
    print("2. é€‰æ‹©åˆé€‚çš„è®­ç»ƒé¢„è®¾:")
    print("   - quick: å¿«é€Ÿå®éªŒï¼ŒéªŒè¯æƒ³æ³•")
    print("   - standard: æ ‡å‡†è®­ç»ƒï¼Œå¹³è¡¡æ•ˆæœ")
    print("   - high_quality: é«˜è´¨é‡è®­ç»ƒï¼Œæœ€ä½³æ•ˆæœ")
    print()
    print("3. ç›‘æ§è®­ç»ƒè¿‡ç¨‹:")
    print("   - è®¿é—® http://localhost:8080 æŸ¥çœ‹å®æ—¶ç›‘æ§")
    print("   - æŸ¥çœ‹è®­ç»ƒæ—¥å¿—äº†è§£è¯¦ç»†ä¿¡æ¯")
    print("   - ä½¿ç”¨WandBè¿›è¡Œå®éªŒç®¡ç†")
    print()
    print("4. ä¿å­˜å’ŒåŠ è½½æ¨¡å‹:")
    print("   - è®­ç»ƒå®Œæˆåæ¨¡å‹è‡ªåŠ¨ä¿å­˜")
    print("   - ä½¿ç”¨ trainer.load_model() åŠ è½½æ¨¡å‹")
    print("   - ä½¿ç”¨ trainer.generate_text() è¿›è¡Œæ¨ç†")
    print()


async def run_all_examples():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸš€ å¼€å§‹è¿è¡ŒNovaMindè®­ç»ƒæ¡†æ¶ç¤ºä¾‹")
    print("=" * 60)
    
    try:
        # å¿«é€Ÿå¼€å§‹
        quick_start_example()
        
        # è¿è¡Œç¤ºä¾‹
        await example_1_basic_training()
        await example_2_lora_training()
        await example_3_instruction_tuning()
        await example_4_monitoring()
        
        # æ˜¾ç¤ºä½¿ç”¨æç¤º
        show_usage_tips()
        
        print("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("ğŸ“– æ›´å¤šä¿¡æ¯è¯·æŸ¥çœ‹æ–‡æ¡£å’Œç¤ºä¾‹ä»£ç ")
        
    except Exception as e:
        print(f"âŒ è¿è¡Œç¤ºä¾‹æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


def simple_training_example():
    """ç®€å•è®­ç»ƒç¤ºä¾‹ - ä¸€è¡Œä»£ç å¯åŠ¨è®­ç»ƒ"""
    print("âš¡ ç®€å•è®­ç»ƒç¤ºä¾‹")
    print("=" * 30)
    
    # ä¸€è¡Œä»£ç å¯åŠ¨è®­ç»ƒ
    config = get_training_config(
        model_preset="dialo-gpt-small",
        training_preset="quick",
        dataset_path="./data/sample_texts.json",
        training_name="simple_example"
    )
    
    trainer = LLMTrainer(config)
    trainer.add_callback(MetricsCallback("simple_example"))
    
    # å¯åŠ¨è®­ç»ƒï¼ˆå¼‚æ­¥ï¼‰
    training_id = training_manager.start_training("simple_example", trainer)
    print(f"âœ… ç®€å•è®­ç»ƒå·²å¯åŠ¨: {training_id}")
    
    return training_id


if __name__ == "__main__":
    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    asyncio.run(run_all_examples())
    
    # æˆ–è€…è¿è¡Œç®€å•ç¤ºä¾‹
    # simple_training_example() 